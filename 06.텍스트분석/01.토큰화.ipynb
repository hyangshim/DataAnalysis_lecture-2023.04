{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화 (Tokenization)\n",
    "    - https://wikidocs.net/21698\n",
    "    - 딥러닝을 위한 자연어 처리 입문,위키독스\n",
    "    - 제2장 .텍스트 전처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 설치 : pip install nltk\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\YONSAI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\YONSAI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\YONSAI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "방법 1: ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
    "print('방법 1:',word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "방법:2 ['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
     ]
    }
   ],
   "source": [
    "print('방법:2',WordPunctTokenizer().tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "트리뱅크 워드토크나이저 : ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
     ]
    }
   ],
   "source": [
    "# 방법 1이랑 똑같음\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "print('트리뱅크 워드토크나이저 :',tokenizer.tokenize(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 토큰화1 : ['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"
     ]
    }
   ],
   "source": [
    "#sent_tokenize문자 .(공백)으로 분리됨\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
    "print('문장 토큰화1 :',sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 토큰화2 : ['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"
     ]
    }
   ],
   "source": [
    "text = \"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n",
    "print('문장 토큰화2 :',sent_tokenize(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한글 문장 토큰화\n",
    "    - pip install kss 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Kss]: Because there's no supported C++ morpheme analyzer, Kss will take pecab as a backend. :D\n",
      "For your information, Kss also supports mecab backend.\n",
      "We recommend you to install mecab or konlpy.tag.Mecab for faster execution of Kss.\n",
      "Please refer to following web sites for details:\n",
      "- mecab: https://cleancode-ws.tistory.com/97\n",
      "- konlpy.tag.Mecab: https://uwgdqo.tistory.com/363\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문장 토큰화 : ['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다.', '이제 해보면 알걸요?']\n"
     ]
    }
   ],
   "source": [
    "import kss\n",
    "\n",
    "text = '딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'\n",
    "print('한국어 문장 토큰화 :',kss.split_sentences(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 한글 토큰화\n",
    "- java 설치(JKD 11)\n",
    "- pio install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "JVMNotFoundException",
     "evalue": "No JVM shared library file (jvm.dll) found. Try setting up the JAVA_HOME environment variable properly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJVMNotFoundException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkonlpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtag\u001b[39;00m \u001b[39mimport\u001b[39;00m Okt\n\u001b[1;32m----> 2\u001b[0m okt \u001b[39m=\u001b[39m Okt()\n\u001b[0;32m      3\u001b[0m okt\u001b[39m.\u001b[39mnouns(text)\n",
      "File \u001b[1;32mc:\\Users\\YONSAI\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:51\u001b[0m, in \u001b[0;36mOkt.__init__\u001b[1;34m(self, jvmpath, max_heap_size)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, jvmpath\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, max_heap_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[0;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m jpype\u001b[39m.\u001b[39misJVMStarted():\n\u001b[1;32m---> 51\u001b[0m         jvm\u001b[39m.\u001b[39;49minit_jvm(jvmpath, max_heap_size)\n\u001b[0;32m     53\u001b[0m     oktJavaPackage \u001b[39m=\u001b[39m jpype\u001b[39m.\u001b[39mJPackage(\u001b[39m'\u001b[39m\u001b[39mkr.lucypark.okt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     54\u001b[0m     OktInterfaceJavaClass \u001b[39m=\u001b[39m oktJavaPackage\u001b[39m.\u001b[39mOktInterface\n",
      "File \u001b[1;32mc:\\Users\\YONSAI\\anaconda3\\lib\\site-packages\\konlpy\\jvm.py:55\u001b[0m, in \u001b[0;36minit_jvm\u001b[1;34m(jvmpath, max_heap_size)\u001b[0m\n\u001b[0;32m     52\u001b[0m args \u001b[39m=\u001b[39m [javadir, os\u001b[39m.\u001b[39msep]\n\u001b[0;32m     53\u001b[0m classpath \u001b[39m=\u001b[39m [f\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m folder_suffix]\n\u001b[1;32m---> 55\u001b[0m jvmpath \u001b[39m=\u001b[39m jvmpath \u001b[39mor\u001b[39;00m jpype\u001b[39m.\u001b[39;49mgetDefaultJVMPath()\n\u001b[0;32m     57\u001b[0m \u001b[39m# NOTE: Temporary patch for Issue #76. Erase when possible.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mplatform \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdarwin\u001b[39m\u001b[39m'\u001b[39m\\\n\u001b[0;32m     59\u001b[0m         \u001b[39mand\u001b[39;00m jvmpath\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m1.8.0\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\\\n\u001b[0;32m     60\u001b[0m         \u001b[39mand\u001b[39;00m jvmpath\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39mlibjvm.dylib\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\YONSAI\\anaconda3\\lib\\site-packages\\jpype\\_jvmfinder.py:74\u001b[0m, in \u001b[0;36mgetDefaultJVMPath\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     finder \u001b[39m=\u001b[39m LinuxJVMFinder()\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m finder\u001b[39m.\u001b[39;49mget_jvm_path()\n",
      "File \u001b[1;32mc:\\Users\\YONSAI\\anaconda3\\lib\\site-packages\\jpype\\_jvmfinder.py:212\u001b[0m, in \u001b[0;36mJVMFinder.get_jvm_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m jvm_notsupport_ext \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[39mraise\u001b[39;00m jvm_notsupport_ext\n\u001b[1;32m--> 212\u001b[0m \u001b[39mraise\u001b[39;00m JVMNotFoundException(\u001b[39m\"\u001b[39m\u001b[39mNo JVM shared library file (\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mfound. Try setting up the JAVA_HOME \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39menvironment variable properly.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m                            \u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libfile))\n",
      "\u001b[1;31mJVMNotFoundException\u001b[0m: No JVM shared library file (jvm.dll) found. Try setting up the JAVA_HOME environment variable properly."
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "okt.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
